{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-83a1IbhX-_"
      },
      "source": [
        "# Assignment 2: Entity Resolution (Part 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj2QphGchX_D"
      },
      "source": [
        "## Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5hlkmoZhX_E"
      },
      "source": [
        "In Assignment 2 (Part 2), you will learn how to use Active Learning to address the entity resolution problem. After completing this assignment, you should be able to answer the following questions:\n",
        "\n",
        "1. Why Active Learning?\n",
        "2. How to implement uncertain sampling, a popular query strategy for Active Learning?\n",
        "3. How to solve an ER problem using Active Learning?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrCCMbYuhX_E"
      },
      "source": [
        "## Active Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD6906m3hX_F"
      },
      "source": [
        "[Active learning](http://tiny.cc/al-wiki) is a certain type of ML algorithms that can train a high-quality ML model with small data-labeling cost. Its basic idea is quite easy to understand. Consider a typical supervised ML problem, which requires a (relatively) large training dataset. In the training dataset, there may be only a small number of data points that are beneficial to the trained ML model. In other words, labeling a small number of data points is enough to train a high-quality ML model. The goal of active learning is to help us to identify those data points. \n",
        "\n",
        "\n",
        "In this assignment, we will develop an Active Learning approach for Entity Resolution. The following figure shows the architecture of an entity resolution solution. It consists of four major steps. **I will provide you the source code for Steps 1, 2, 4. Your job is to implement Step 3.**  \n",
        "\n",
        "<img src=\"img/arch.png\", width=800/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAoKQKIFhX_G"
      },
      "source": [
        "![title](img/arch.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1tHsjv5hX_G"
      },
      "source": [
        "### Step 1. Read Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wscCq8W1hX_H"
      },
      "source": [
        "Suppose we get a restaurant dataset `restaurant.csv`. The data has many duplicate restaurants.  For example, the first two rows shown below are duplicated (i.e., refer to the same real-world entity). You can check out all duplicate (matching) record pairs from `true_matches.json`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "0C1D3TqzhX_I",
        "outputId": "3dfc65e1-3912-41ae-d815-77956c7ab7eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#Rows, #Cols) : (858, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a8e76563-7e4c-42e8-8f8c-2cde9b0e84d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>address</th>\n",
              "      <th>city</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>arnie morton's of chicago</td>\n",
              "      <td>435 s. la cienega blv.</td>\n",
              "      <td>los angeles</td>\n",
              "      <td>american</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>arnie morton's of chicago</td>\n",
              "      <td>435 s. la cienega blvd.</td>\n",
              "      <td>los angeles</td>\n",
              "      <td>steakhouses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>art's delicatessen</td>\n",
              "      <td>12224 ventura blvd.</td>\n",
              "      <td>studio city</td>\n",
              "      <td>american</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>art's deli</td>\n",
              "      <td>12224 ventura blvd.</td>\n",
              "      <td>studio city</td>\n",
              "      <td>delis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>hotel bel-air</td>\n",
              "      <td>701 stone canyon rd.</td>\n",
              "      <td>bel air</td>\n",
              "      <td>californian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8e76563-7e4c-42e8-8f8c-2cde9b0e84d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8e76563-7e4c-42e8-8f8c-2cde9b0e84d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8e76563-7e4c-42e8-8f8c-2cde9b0e84d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id                       name  ...         city         type\n",
              "0   1  arnie morton's of chicago  ...  los angeles     american\n",
              "1   2  arnie morton's of chicago  ...  los angeles  steakhouses\n",
              "2   3         art's delicatessen  ...  studio city     american\n",
              "3   4                 art's deli  ...  studio city        delis\n",
              "4   5              hotel bel-air  ...      bel air  californian\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('restaurant.csv')\n",
        "data = df.values.tolist()\n",
        "print(\"(#Rows, #Cols) :\", df.shape)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Q60fZEhX_J"
      },
      "source": [
        "### Step 2. Similar Pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_eDbAWfhX_K"
      },
      "source": [
        "We first use a similarity-join algorithm to generate similar pairs. \n",
        "\n",
        "Below is the code. After running the code, we get 678 similar pairs ordered by their similarity decreasingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgvlwC9ThX_K",
        "outputId": "c84d1f3d-45f7-4bc5-a702-5e297fea92e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of Pairs:  367653.0\n",
            "Num of Similar Pairs:  678\n",
            "The Most Similar Pair:  ([170, \"mary mac's tea room\", '224 ponce de leon ave.', 'atlanta', 'southern/soul'], [169, \"mary mac's tea room\", '224 ponce de leon ave.', 'atlanta', 'southern'])\n"
          ]
        }
      ],
      "source": [
        "from a2_utils import *\n",
        "\n",
        "data = df.values.tolist()\n",
        "simpairs = simjoin(data)\n",
        "\n",
        "print(\"Num of Pairs: \", len(data)*(len(data)-1)/2)\n",
        "print(\"Num of Similar Pairs: \", len(simpairs))\n",
        "print(\"The Most Similar Pair: \", simpairs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGEUZB4ChX_L"
      },
      "source": [
        "We can see that `simjoin` helps us remove the number of pairs from 367653 to 678. But, there are still many non-matching pairs in `simpairs` (see below). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yopYJ8SmhX_L",
        "outputId": "097b0f58-04a9-40ee-9e81-74f79b455b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([764, \"buzio's in the rio\", '3700 w. flamingo rd.', 'las vegas', 'seafood'], [542, 'carnival world', '3700 w. flamingo rd.', 'las vegas', 'buffets'])\n"
          ]
        }
      ],
      "source": [
        "print(simpairs[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snHuF-ZdhX_M"
      },
      "source": [
        "Next, we will use active learning to train a classifier, and then use the classifier to classify each pair in `simpairs` as either \"matching\" or \"nonmatching\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPkL5IwKhX_M"
      },
      "source": [
        "### Step 3. Active Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ro1w1EqhX_N"
      },
      "source": [
        "Given a set of similar pairs, what you need to do next is to iteratively train a classifier to decide which pairs are truly matching. We are going to use [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) as our classifier. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVUNEI8hhX_N"
      },
      "source": [
        "#### Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f0_bLE7hX_O"
      },
      "source": [
        "At the beginning, all the pairs are unlabeled. To initialize a model, we first pick up ten pairs and then label each pair using  the `crowdsourcing()` function. You can assume that `crowdsourcing()` will ask a crowd worker (e.g., on Amazon Mechanical Turk) to label a pair. \n",
        "\n",
        "\n",
        "`crowdsourcing(pair)` is a function that simulates the use of crowdsourcing to label a pair\n",
        "  \n",
        "  - **Input:**\tpair – A pair of records \n",
        "\n",
        "  - **Output:**\tBoolean –  *True*: The pair of records are matching; *False*: The pair of records are NOT matching;\n",
        "\n",
        "Please use the following code to do the initialization. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRLAKH8_hX_P",
        "outputId": "5f7557df-6e4b-4881-b676-045a56be8cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[170, \"mary mac's tea room\", '224 ponce de leon ave.', 'atlanta', 'southern/soul']\n",
            "[169, \"mary mac's tea room\", '224 ponce de leon ave.', 'atlanta', 'southern']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[88, 'manhattan ocean club', '57 w. 58th st.', 'new york city', 'seafood']\n",
            "[87, 'manhattan ocean club', '57 w. 58th st.', 'new york', 'seafood']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[112, 'san domenico', '240 central park s.', 'new york city', 'italian']\n",
            "[111, 'san domenico', '240 central park s', 'new york', 'italian']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[197, 'fleur de lys', '777 sutter st.', 'san francisco', 'french (new)']\n",
            "[196, 'fleur de lys', '777 sutter st.', 'san francisco', 'french']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[8, 'cafe bizou', '14016 ventura blvd.', 'sherman oaks', 'french bistro']\n",
            "[7, 'cafe bizou', '14016 ventura blvd.', 'sherman oaks', 'french']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[709, 'arcadia', '21 e. 62nd st.', 'new york city', 'american (new)']\n",
            "[66, 'four seasons', '99 e. 52nd st.', 'new york city', 'american (new)']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[709, 'arcadia', '21 e. 62nd st.', 'new york city', 'american (new)']\n",
            "[70, 'gramercy tavern', '42 e. 20th st.', 'new york city', 'american (new)']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[729, 'la grenouille', '3 e. 52nd st.', 'new york city', 'french (classic)']\n",
            "[60, 'daniel', '20 e. 76th st.', 'new york city', 'french (new)']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[733, 'menchanko-tei', '39 w. 55th st.', 'new york city', 'japanese']\n",
            "[76, 'la caravelle', '33 w. 55th st.', 'new york city', 'french (classic)']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[764, \"buzio's in the rio\", '3700 w. flamingo rd.', 'las vegas', 'seafood']\n",
            "[542, 'carnival world', '3700 w. flamingo rd.', 'las vegas', 'buffets']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "Number of matches:  5\n",
            "Number of nonmatches:  5\n"
          ]
        }
      ],
      "source": [
        "from a2_utils import crowdsourcing\n",
        "\n",
        "# choose the most/least similar five pairs as initial training data\n",
        "init_pairs = simpairs[:5] + simpairs[-5:]\n",
        "matches = []\n",
        "nonmatches = []\n",
        "for pair in init_pairs:\n",
        "    is_match = crowdsourcing(pair)\n",
        "    if is_match == True:\n",
        "        matches.append(pair)\n",
        "    else:\n",
        "        nonmatches.append(pair)\n",
        "        \n",
        "print(\"Number of matches: \", len(matches))\n",
        "print(\"Number of nonmatches: \", len(nonmatches))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcpSEotLhX_Q"
      },
      "source": [
        "Here is the only code you need to write in this assignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gcKZ2jFthX_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece42197-20db-4dd1-9a65-7fbc1a4c5907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[817, 'ritz-carlton cafe (atlanta)', '181 peachtree st.', 'atlanta', 'american (new)']\n",
            "[180, 'ritz-carlton restaurant', '181 peachtree st.', 'atlanta', 'french (classic)']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[555, \"ralph's diner\", '3000 las vegas blvd. s', 'las vegas', 'coffee shops/diners']\n",
            "[538, \"bugsy's diner\", '3555 las vegas blvd. s', 'las vegas', 'coffee shops/diners']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[4, \"art's deli\", '12224 ventura blvd.', 'studio city', 'delis']\n",
            "[3, \"art's delicatessen\", '12224 ventura blvd.', 'studio city', 'american']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[156, 'ciboulette restaurant', '1529 piedmont ave.', 'atlanta', 'french (new)']\n",
            "[155, 'ciboulette', '1529 piedmont ave.', 'atlanta', 'french']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[130, \"virgil's real bbq\", '152 w. 44th st.', 'new york city', 'bbq']\n",
            "[129, \"virgil's\", '152 w. 44th st.', 'new york', 'american']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[24, 'le chardonnay (los angeles)', '8284 melrose ave.', 'los angeles', 'french bistro']\n",
            "[23, 'le chardonnay', '8284 melrose ave.', 'los angeles', 'french']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[817, 'ritz-carlton cafe (atlanta)', '181 peachtree st.', 'atlanta', 'american (new)']\n",
            "[179, 'restaurant  ritz-carlton  atlanta', '181 peachtree st.', 'atlanta', 'continental']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[42, \"yujean kang's\", '67 n. raymond ave.', 'pasadena', 'chinese']\n",
            "[41, \"yujean kang's gourmet chinese cuisine\", '67 n. raymond ave.', 'los angeles', 'asian']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[217, 'ritz-carlton dining room (san francisco)', '600 stockton st.', 'san francisco', 'french (new)']\n",
            "[216, 'ritz-carlton restaurant and dining room', '600 stockton st.', 'san francisco', 'american']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[501, \"dante's down the hatch\", 'underground underground mall  underground atlanta', 'atlanta', 'continental']\n",
            "[500, \"dante's down the hatch  buckhead\", '3380 peachtree rd.', 'atlanta', 'continental']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "658\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[178, 'ritz-carlton dining room (buckhead)', '3434 peachtree rd. ne', 'atlanta', 'american (new)']\n",
            "[175, 'cafe  ritz-carlton  buckhead', '3434 peachtree rd.', 'atlanta', 'ext 6108 international']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[177, 'dining room  ritz-carlton  buckhead', '3434 peachtree rd.', 'atlanta', 'international']\n",
            "[176, 'ritz-carlton cafe (buckhead)', '3434 peachtree rd. ne', 'atlanta', 'american (new)']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[26, 'locanda veneta', '8638 w. third st.', 'los angeles', 'italian']\n",
            "[25, 'locanda veneta', '3rd st.', 'los angeles', 'italian']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[152, 'brasserie le coze', '3393 peachtree rd.', 'atlanta', 'french bistro']\n",
            "[151, 'brasserie le coze', '3393 peachtree rd.  lenox square mall  near neiman marcus', 'atlanta', 'french']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[545, 'empress court', '3570 las vegas blvd. s', 'las vegas', 'asian']\n",
            "[137, 'palace court', '3570 las vegas blvd. s', 'las vegas', 'continental']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[545, 'empress court', '3570 las vegas blvd. s', 'las vegas', 'asian']\n",
            "[138, 'palace court', '3570 las vegas blvd. s.', 'las vegas', 'french (new)']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[146, 'abruzzi', '2355 peachtree rd. ne', 'atlanta', 'italian']\n",
            "[145, 'abruzzi', '2355 peachtree rd.  peachtree battle shopping center', 'atlanta', 'italian']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[603, \"mccormick & kuleto's\", 'ghirardelli sq.', 'san francisco', 'seafood']\n",
            "[579, \"gaylord's\", 'ghirardelli sq.', 'san francisco', 'asian']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[110, 'river cafe', '1 water st.', 'brooklyn', 'american (new)']\n",
            "[109, 'river cafe', '1 water st. at the east river', 'brooklyn', 'american']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[168, 'la grotta', '2637 peachtree rd. ne', 'atlanta', 'italian']\n",
            "[167, 'la grotta', '2637 peachtree rd.  peachtree house condominium', 'atlanta', 'italian']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "648\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[207, 'lulu restaurant-bis-cafe', '816 folsom st.', 'san francisco', 'mediterranean']\n",
            "[206, 'lulu', '816 folsom st.', 'san francisco', 'mediterranean']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[741, 'palm too', '840 second ave.', 'new york city', 'steakhouses']\n",
            "[740, 'palm', '837 second ave.', 'new york city', 'steakhouses']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[160, 'georgia grille', '2290 peachtree rd.', 'atlanta', 'southwestern']\n",
            "[159, 'georgia grille', '2290 peachtree rd.  peachtree square shopping center', 'atlanta', 'american']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[195, 'chez michel', '804 north point st.', 'san francisco', 'californian']\n",
            "[194, 'chez michel', '804 northpoint', 'san francisco', 'french']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[459, 'stage deli', '834 7th ave.  between 53rd and 54th sts.', 'new york', 'delicatessen']\n",
            "[55, 'carnegie deli', '854 7th ave.  between 54th and 55th sts.', 'new york', 'delicatessen']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[136, 'le montrachet bistro', '3000 paradise rd.', 'las vegas', 'french bistro']\n",
            "[135, 'le montrachet', '3000 w. paradise rd.', 'las vegas', 'continental']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[78, 'la cote basque', '60 w. 55th st.', 'new york city', 'french (classic)']\n",
            "[75, 'la caravelle', '33 w. 55th st.', 'new york', 'french']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[126, \"uncle nick's\", '747 ninth ave.', 'new york city', 'greek']\n",
            "[125, \"uncle nick's\", '747 9th ave.  between 50th and 51st sts.', 'new york', 'mediterranean']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[148, 'bacchanalia', '3125 piedmont rd.', 'atlanta', 'californian']\n",
            "[147, 'bacchanalia', '3125 piedmont rd.  near peachtree rd.', 'atlanta', 'international']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[307, 'cafe botanica', '160 central park s', 'new york', 'french']\n",
            "[81, 'les celebrites', '160 central park s', 'new york', 'french']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "638\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[817, 'ritz-carlton cafe (atlanta)', '181 peachtree st.', 'atlanta', 'american (new)']\n",
            "[176, 'ritz-carlton cafe (buckhead)', '3434 peachtree rd. ne', 'atlanta', 'american (new)']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[316, 'caffe reggio', '119 macdougal st.  between 3rd and bleecker sts.', 'new york', 'coffee bar']\n",
            "[313, 'caffe dante', '81 macdougal st.  between houston and bleeker sts.', 'new york', 'coffee bar']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[78, 'la cote basque', '60 w. 55th st.', 'new york city', 'french (classic)']\n",
            "[76, 'la caravelle', '33 w. 55th st.', 'new york city', 'french (classic)']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[270, 'sofi', '3rd st.', 'los angeles', 'mediterranean']\n",
            "[230, 'cava', '3rd st.', 'los angeles', 'mediterranean']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[302, 'bruno', '240 e. 58th st.', 'new york', 'italian']\n",
            "[64, 'felidia', '243 e. 58th st.', 'new york city', 'italian']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[388, 'la reserve', '4 w. 49th st.', 'new york', 'french']\n",
            "[76, 'la caravelle', '33 w. 55th st.', 'new york city', 'french (classic)']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[211, 'mifune', '1737 post st.', 'san francisco', 'japanese']\n",
            "[210, 'mifune japan center  kintetsu building', '1737 post st.', 'san francisco', 'asian']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[778, \"stefano's\", '129 fremont st.', 'las vegas', 'italian']\n",
            "[549, \"lillie langtry's\", '129 e. fremont st.', 'las vegas', 'asian']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[759, \"wollensky's grill\", '205 e. 49th st.', 'new york city', 'steakhouses']\n",
            "[121, 'smith & wollensky', '201 e. 49th st.', 'new york', 'american']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[361, \"gallagher's\", '228 w. 52nd st.', 'new york', 'american']\n",
            "[294, \"ben benson's\", '123 w. 52nd st.', 'new york', 'american']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "628\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[20, 'katsu', '1972 hillhurst ave.', 'los feliz', 'japanese']\n",
            "[19, 'restaurant katsu', '1972 n. hillhurst ave.', 'los angeles', 'asian']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[84, 'lespinasse (new york city)', '2 e. 55th st.', 'new york city', 'asian']\n",
            "[83, 'lespinasse', '2 e. 55th st.', 'new york', 'american']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[144, 'tillerman  the', '2245 e. flamingo rd.', 'las vegas', 'steakhouses']\n",
            "[143, 'tillerman', '2245 e. flamingo rd.', 'las vegas', 'seafood']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[174, \"pano's & paul's\", '1232 w. paces ferry rd.', 'atlanta', 'american (new)']\n",
            "[173, \"pano's and paul's\", '1232 w. paces ferry rd.', 'atlanta', 'international']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[114, 'second avenue deli', '156 second ave.', 'new york city', 'delis']\n",
            "[113, 'second avenue deli', '156 2nd ave. at 10th st.', 'new york', 'delicatessen']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[177, 'dining room  ritz-carlton  buckhead', '3434 peachtree rd.', 'atlanta', 'international']\n",
            "[175, 'cafe  ritz-carlton  buckhead', '3434 peachtree rd.', 'atlanta', 'ext 6108 international']\n",
            "\u001b[1;31mAnswer: No\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[134, 'coyote cafe (las vegas)', '3799 las vegas blvd. s.', 'las vegas', 'southwestern']\n",
            "[133, 'coyote cafe', '3799 las vegas blvd. s', 'las vegas', 'southwestern']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[164, 'heera of india', '595 piedmont ave.', 'atlanta', 'indian']\n",
            "[163, 'heera of india', '595 piedmont ave.  rio shopping mall', 'atlanta', 'asian']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[180, 'ritz-carlton restaurant', '181 peachtree st.', 'atlanta', 'french (classic)']\n",
            "[179, 'restaurant  ritz-carlton  atlanta', '181 peachtree st.', 'atlanta', 'continental']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "\u001b[1;31mAre they matching?\u001b[0m\n",
            "[140, 'second street grill', '200 e. fremont st.', 'las vegas', 'pacific rim']\n",
            "[139, 'second street grille', '200 e. fremont st.', 'las vegas', 'seafood']\n",
            "\u001b[1;31mAnswer: Yes\u001b[0m\n",
            "618\n"
          ]
        }
      ],
      "source": [
        "from a2_utils import featurize, crowdsourcing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "labeled_pairs = matches + nonmatches\n",
        "unlabeled_pairs = [featurize(p) for p in simpairs if p not in labeled_pairs]\n",
        "unlabel_unfea_pairs = [p for p in simpairs if p not in labeled_pairs]\n",
        "iter_num = 5\n",
        "df_predict=[]\n",
        "labeled_pairs=[featurize(p) for p in labeled_pairs]\n",
        "y=[1,1,1,1,1,0,0,0,0,0]\n",
        "test_pairs=unlabeled_pairs\n",
        "\n",
        "for iter in range(iter_num):\n",
        "  df_predict=[]\n",
        "  model=LogisticRegression().fit(labeled_pairs,y)\n",
        "  df_predict=model.predict(test_pairs)\n",
        "  df_prob=model.predict_proba(test_pairs)\n",
        "  df_proba1=pd.DataFrame(df_prob)\n",
        "  df_proba1.columns=['prob0', 'prob1']\n",
        "  df_proba1[\"diff\"]=abs(df_proba1[\"prob1\"]-df_proba1[\"prob0\"])\n",
        "  df_proba1[\"pairs\"]=[x for x in test_pairs]\n",
        "  df_proba1[\"original_pairs\"]=[x for x in unlabel_unfea_pairs]\n",
        "  df_proba1=df_proba1.sort_values(ascending=False,by=\"diff\")\n",
        "  df_proba1=df_proba1.reset_index(drop=True)\n",
        "  for i in range(10):\n",
        "    is_match = crowdsourcing(df_proba1[\"original_pairs\"][len(df_proba1)-i-1])\n",
        "    if is_match == True:\n",
        "        y.append(1)\n",
        "        labeled_pairs.append(df_proba1[\"pairs\"][len(test_pairs)-i-1])\n",
        "        test_pairs.remove(df_proba1[\"pairs\"][len(df_proba1)-i-1])\n",
        "        unlabel_unfea_pairs.remove(df_proba1[\"original_pairs\"][len(df_proba1)-i-1])\n",
        "    else:\n",
        "        y.append(0)\n",
        "        labeled_pairs.append(df_proba1[\"pairs\"][len(df_proba1)-i-1])\n",
        "        test_pairs.remove(df_proba1[\"pairs\"][len(df_proba1)-i-1])\n",
        "        unlabel_unfea_pairs.remove(df_proba1[\"original_pairs\"][len(df_proba1)-i-1])\n",
        "  print(len(test_pairs))\n",
        "  \n",
        "\n",
        "#<-- Write Your Code -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo4-8lr7hX_R"
      },
      "source": [
        "**[Algorithm Description].**   Active learning has many [query strategies](http://tiny.cc/al-wiki-qs) to decide which data point should be labeled. You need to implement uncertain sampling. The algorithm trains an initial model on `labeled_pairs`. Then, it iteratively trains a model. At each iteration, it first applies the model to `unlabeled_pairs`, and makes a prediction on each unlabeled pair along with a probability, where the probability indicates the confidence of the prediction. After that, it selects the most uncertain pair (If there is still a tie, break it randomly),  and call the `crowdsroucing()` function to label the pair. After the pair is labeled, it updates `labeled_pairs` and `unlabeled_pairs`, and then retrain the model on `labeled_pairs`.\n",
        "\n",
        "**[Input].** \n",
        "- `labeled_pairs`: 10 labeled pairs (by default)\n",
        "- `unlabeled_pairs`: 668 unlabeled pairs (by default)\n",
        "- `iter_num`: 5 (by default)\n",
        "\n",
        "**[Output].** \n",
        "- `model`: A logistic regression model built by scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFN1TxnIhX_S"
      },
      "source": [
        "### Step 4. Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg0lWwuEhX_T"
      },
      "source": [
        "After training an model, you can use the following code to evalute it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9eUCkkRhX_T",
        "outputId": "dbf8c13b-03bb-45f1-88e3-4b5bf6ee9fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.96\n",
            "Recall: 0.9056603773584906\n",
            "Fscore: 0.9320388349514563\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from a2_utils import evaluate\n",
        "import numpy as np\n",
        "            \n",
        "sp_features = np.array([featurize(sp) for sp in simpairs])\n",
        "label = model.predict(sp_features)\n",
        "pair_label = zip(simpairs, label)\n",
        "\n",
        "identified_matches = []\n",
        "for pair, label in pair_label:\n",
        "    if label == 1:\n",
        "        identified_matches.append(pair)\n",
        "        \n",
        "precision, recall, fscore = evaluate(identified_matches)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Fscore:\", fscore)\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7aujYyGhX_U"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ddqFjTDhX_U"
      },
      "source": [
        "Complete the code in A2-2.ipynb, and submit it to the CourSys activity Assignment 2."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "A2-2.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}